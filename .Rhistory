macd_checked_60M <- readRDS("C:/DSS_Bot/DSS_R/_DATA/macd_checked_60M.rds")
View(macd_checked_60M)
time_execute <- readRDS("C:/DSS_Bot/DSS_R/_LOGS/time_execute.rds")
View(time_execute)
# 20200913 - Analysing Model Testing results
library(ggplot2)
library(magrittr)
## read files with predicted price changes
#path to user repo:
#!!!Change this path!!!
path_user <- "C:/DSS_Bot/DSS_R"
#path to store logs data (e.g. duration of machine learning steps)
path_logs <- file.path(path_user, "_MODELS")
# file names
filesToAnalyse <-list.files(path = path_logs,
pattern = "-60.rds",
full.names=TRUE)
# aggregate all files into one
for (VAR in filesToAnalyse) {
# VAR <- filesToAnalyse[1]
if(!exists("dfres")){dfres <- readr::read_rds(VAR)}  else {
dfres <- readr::read_rds(VAR) %>% dplyr::bind_rows(dfres)
}
}
# visualized
ggplot(dfres, aes(x = NB_hold, y = PnL_NB,
#size = TotalTrades,
col = as.factor(Symbol)))+geom_point()+
ggtitle("Strategy Test results")
## Analysis of model quality records
# file names
filesToAnalyse1 <-list.files(path = path_logs,
pattern = "M60.csv",
full.names=TRUE)
# aggregate all files into one
for (VAR in filesToAnalyse1) {
# VAR <- filesToAnalyse1[1]
if(!exists("dfres1")){dfres1 <- readr::read_csv(VAR)}  else {
dfres1 <- readr::read_csv(VAR) %>% dplyr::bind_rows(dfres1)
}
}
# visualized
ggplot(dfres1, aes(x = MaxPerf, y = Symbol,
col = TR_Level,
size = NB_hold))+geom_point()+
geom_vline(xintercept=0.001)+
scale_x_continuous()+
ggtitle("Model Performance")
#scale_x_continuous(trans='log10')+
#ggtitle("Model Performance", "x axis at log 10 scale")
#readr::write_rds(dfres1,
#                 "C:/Users/fxtrams/Documents/6_CoursesUdemy/03_Lazy_Trading_Series/7_SelflearningAI/Simulations/NeuralNetworkInputsDoE/6.03/dfres.rds")
View(dfres1)
write_command_via_csv(dfres1,paste0(path_user,'_LOG', fileName = 'dfres1'))
path_user <- normalizePath(Sys.getenv(PATH_DSS), winslash = '/')
path_user <- normalizePath(Sys.getenv("PATH_DSS"), winslash = '/')
paste0(path_user,"_DATA")
write.csv(dfres1,paste0(path_user,"/_DATA", row.names=FALSE))
write.csv(dfres1,paste0(path_user,"/_DATA/analyse_resultM60.csv", row.names=FALSE))
write.csv(dfres1,paste0(path_user,"/_DATA/analyse_resultM60.csv"), row.names=FALSE))
write.csv(dfres1,paste0(path_user,"/_DATA/analyse_resultM60.csv"), row.names=FALSE)
write.csv(dfres1,paste0(path_user,"/_DATA/analyse_resultM60.csv"), row.names=FALSE)
write.csv(dfres,paste0(path_user,"/_DATA/analyse_resultM60_data.csv"), row.names=FALSE)
shiny::runApp('Monitor')
runApp('Monitor')
path_user <- normalizePath(Sys.getenv('PATH_DSS'), winslash = '/')
path_data <- file.path(path_user, "_DATA")
macd_ai <- readr::read_rds(file.path(path_data, 'macd_ai_classified.rds'))
get_data <- function(){
macd_ai <- readr::read_rds(file.path(path_data, 'macd_ai_classified.rds'))
return(macd_ai)}
macd_ai <- get_data()
write_data <- function(x){
readr::write_rds(x, file.path(path_data, 'macd_ai_classified.rds'))
}
file_checked <- file.path(path_data, "macd_checked_60M.rds")
storeData <- function(data, fileName) {
# store store gathered unique records
# non duplicates
nonDuplicate <- data[!duplicated(data), ]
# read existing file, if that exists...
if(file.exists(fileName)){
ex_data <- readr::read_rds(fileName)
# append...
agr_data <- dplyr::bind_rows(ex_data, nonDuplicate)
# Write the file to the local system
readr::write_rds(x = agr_data, file = fileName)
# write data first time...
} else {
# Write the file to the local system
readr::write_rds(x = nonDuplicate, file = fileName)
}
}
n_rows <- reactiveValues(c = nrow(macd_ai))
runApp('Monitor')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='stufflow',
token='B2CF01594550BF545F5036F19AB4E579',
secret='<SECRET>')
rsconnect::setAccountInfo(name='stufflow',
token='B2CF01594550BF545F5036F19AB4E579',
secret='<SECRET>')
rsconnect::setAccountInfo(name='stufflow',
token='B2CF01594550BF545F5036F19AB4E579',
secret='P/luHe0wvHXGQBMLzM4DN8MXp7f10m3H02dPnDIP')
runApp('Monitor')
runApp('Monitor')
runApp('Monitor')
runApp('Monitor')
runApp('Monitor')
library(h2o)
runApp('Monitor')
runApp('Monitor')
AccountResultsT1 <- readRDS("C:/DSS_Bot/DSS_R/_DATA/AccountResultsT1.rds")
View(AccountResultsT1)
runApp('Monitor')
runApp('Monitor')
# shutdown h2o
h2o.shutdown(prompt = F)
library(h2o)
# shutdown h2o
h2o.shutdown(prompt = F)
# 20210207 - Analysing Model Structures to discover what are the structures used by most performing models?
library(h2o)
library(magrittr)
library(stringr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(readr)
## read files with predicted price changes
#path to user repo:
path_user <- normalizePath(Sys.getenv('PATH_DSS'), winslash = '/')
timeframe <- 60
#path to store logs data (e.g. duration of machine learning steps)
path_models <- file.path(path_user, "_MODELS")
name_pattern <- paste0("DL_Regression-[A-Z]{6}-", timeframe)
# file names
filesToAnalyse <-list.files(path = path_models,
pattern = name_pattern,
full.names=TRUE)
h2o.init(nthreads = 1)
# extract neural network structures into one table!
for (VAR in filesToAnalyse) {
# VAR <- filesToAnalyse[1]
#load model h2o
ModelR <- h2o::h2o.loadModel(path = VAR)
layers <- ModelR@parameters[["hidden"]]
#find symbol number from the model path
pair <- str_extract(VAR, pattern = name_pattern) %>% str_extract(pattern = "[A-Z]{6}")
#rm(dfres)
if(!exists("dfres"))
{
dfres <- data.frame(Symbol = pair, L1 = layers[1], L2 = layers[2], L3 = layers[3])
} else {
dfres <- data.frame(Symbol = pair, L1 = layers[1], L2 = layers[2], L3 = layers[3]) %>%
bind_rows(dfres)
}
}
h2o.shutdown(prompt = FALSE)
Sys.sleep(3)
# make this in a long format
dfres1 <- pivot_longer(data = dfres,
cols = !Symbol,
names_to = 'Levels',
values_to = 'Neurons')
# visualized
ggplot(dfres1, aes(x = Levels, y = Neurons,
col = as.factor(Symbol)))+geom_point()+
ggtitle("NN Common Structures Analysis")
## Analysis of model quality records
# file names
filesToAnalyse1 <-list.files(path = path_models,
pattern = paste0("M",timeframe,".csv"),
full.names=TRUE)
# aggregate all files into one
for (VAR in filesToAnalyse1) {
# VAR <- filesToAnalyse1[1]
if(!exists("dfres2")){dfres2 <- readr::read_csv(VAR)}  else {
dfres2 <- readr::read_csv(VAR) %>% dplyr::bind_rows(dfres2)
}
}
# get only symbol and max perf
dfres3 <- dfres2 %>% select(Symbol, MaxPerf, FrstQntlPerf) %>%
#join it to the model structrues file
inner_join(dfres1) %>%
#split into good and bad models
mutate(Model_Type = if_else(MaxPerf > FrstQntlPerf, 'Good', 'Bad'))
# visualized together
# ggplot(dfres3, aes(x = Levels, y = Neurons,
#                    size = MaxPerf,
#                    col = as.factor(Symbol)))+geom_point()+
#   ggtitle("NN Common Structures Analysis")+
#   facet_grid(Levels ~ Model_Type)
ggplot(dfres3, aes(x=Levels, y=Neurons, fill=Model_Type)) + # fill=name allow to automatically dedicate a color for each group
geom_violin() +
facet_grid(. ~ Model_Type)
#save dataset for next week
path_logs <- file.path(path_user, "_LOGS", paste0("neurons",timeframe,".rds"))
if(!file.exists(path_logs)){
write_rds(dfres3, path_logs)
} else {
read_rds(path_logs) %>% bind_rows(dfres3) %>%
write_rds(path_logs)
}
# review updated graph
read_rds(path_logs) %>%
ggplot(aes(x=Levels, y=Neurons, fill=Model_Type)) + # fill=name allow to automatically dedicate a color for each group
geom_violin() +
facet_grid(. ~ Model_Type)
###======== record absolute performance of all models
df_rec <- dfres2 %>%
summarise(TimeTest = Sys.time(),
MeanPerf = mean(MaxPerf),
Quantil = mean(FrstQntlPerf))
#save this logs
path_logs1 <- file.path(path_user, "_LOGS", paste0("perf_logs",timeframe,".rds"))
if(!file.exists(path_logs1)){
write_rds(df_rec, path_logs1)
} else {
read_rds(path_logs1) %>% bind_rows(df_rec) %>%
write_rds(path_logs1)
}
perf_logs60 <- readRDS("C:/DSS_Bot/DSS_R/_LOGS/perf_logs60.rds")
View(perf_logs60)
shiny::runApp('Monitor')
runApp('Monitor')
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# THIS CODE IS NOT COMPATIBLE WITH CODE IN FOLDER _RL/TradeTriggerRL.R !!!!!!!
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
start_run <- Sys.time()
# packages used *** make sure to install these packages
library(readr)
library(stringr)
library(dplyr)
library(lubridate)
library(ReinforcementLearning)
library(magrittr)
library(lazytrade)
# -------------------------
# Define terminals path addresses, from where we are going to read/write data
# -------------------------
# terminal 1,3 paths
path_T1 <- normalizePath(Sys.getenv('PATH_T1'), winslash = '/')
path_T3 <- normalizePath(Sys.getenv('PATH_T3'), winslash = '/')
#path to user repo:
path_user <- normalizePath(Sys.getenv('PATH_DSS'), winslash = '/')
#path to bot setup file:
path_bot <- normalizePath(Sys.getenv('PATH_DSS_Bot'), winslash = '/')
# path with folder containing control parameters
path_control_files = file.path(path_user, "_DATA/control")
# # evaluate data on macroeconomic event (required to start trading) DSS_Bot
evaluate_macroeconomic_event(setup_file_path = path_bot,
setup_file_name = "SetupDSS_Bot.csv",
macro_event_path = path_T1,
macro_file_name = "01_MacroeconomicEvent.csv",
path_T1 = path_T1, path_T3 = path_T3)
# -------------------------
# read data from trades in terminal 1
# -------------------------
# # uncomment code below to test functionality without MT4 platform installed
# DFT1 <- try(import_data(trade_log_file = "_TEST_DATA/OrdersResultsT1.csv",
#                         demo_mode = T),
#             silent = TRUE)
DFT1 <- try(import_data(path_T1, "OrdersResultsT1.csv"), silent = TRUE)
# -------------------------
# read data from trades in terminal 3
# -------------------------
DFT3 <- try(import_data(path_T3, "OrdersResultsT3.csv"), silent = TRUE)
# Vector with unique Trading Systems
vector_systems <- DFT1 %$% MagicNumber %>% unique() %>% sort()
DFT1_sum <- DFT1 %>%
group_by(MagicNumber) %>%
summarise(Num_Trades = n(),
Mean_profit = sum(Profit)) %>%
arrange(desc(Num_Trades))
View(DFT1_sum)
i <- 2
# extract current magic number id
trading_system <- vector_systems[i]
trading_systemDF <- DFT1 %>% filter(MagicNumber == trading_system)
DFT1_MT <- try(mt_import_data(path_sbxm = path_T1,
system_number =  trading_system),
silent = TRUE) %>%
filter(TicketNumber != -1)
View(DFT1_MT)
i <- 5
# extract current magic number id
trading_system <- vector_systems[i]
# get trading summary data only for one system
trading_systemDF <- DFT1 %>% filter(MagicNumber == trading_system)
# try to extract market type information for that system, filter rows where MarketType was not logged!
DFT1_MT <- try(mt_import_data(path_sbxm = path_T1,
system_number =  trading_system),
silent = TRUE) %>%
filter(TicketNumber != -1)
View(DFT1_MT)
trading_systemDF <- inner_join(trading_systemDF, DFT1_MT, by = "TicketNumber")
#==============================================================================
# Define state and action sets for Reinforcement Learning
states <- c("BUN", "BUV", "BEN", "BEV", "RAN", "RAV")
actions <- c("ON", "OFF") # 'ON' and 'OFF' are referring to decision to trade with Slave system
# Use optimal control parameters found by auxiliary function
control <- read_rds(paste0(path_control_files,"/", trading_system, ".rds"))
policy_tr_systDF <- rl_generate_policy_mt(x = trading_systemDF,
states = states,
actions = actions,
control = control)
View(policy_tr_systDF)
rl_record_policy_mt(x = policy_tr_systDF,
trading_system = trading_system,
path_terminal = path_T3,
fileName = "SystemControlMT")
install.packages("C:/Users/Administrator/Downloads/lazytrade_0.4.5.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Administrator/Downloads/lazytrade_0.4.5.tar.gz", repos = NULL, type = "source")
# This is a dedicated script for the Lazy Trading 4th Course: Statistical Analysis and Control of Trades
# This is a dedicated script for the Lazy Trading 6th Course: Detect Market Type with Artificial Intelligence
# Copyright (C) 2019 Vladimir Zhbanko
# Preferrably to be used only with the courses Lazy Trading see: https://vladdsm.github.io/myblog_attempt/index.html
# https://www.udemy.com/course/your-trading-control-reinforcement-learning/?referralCode=7AB82127FC5C2334AE8D
# https://www.udemy.com/course/detect-market-status-with-ai/?referralCode=B5158326287C6D2C0DEF
# PURPOSE: Analyse trade results in Terminal 1 and Trigger or Stop Trades in Terminal 3
# DETAILS: Trades are analysed and RL model is created for each single Expert Advisor
#        : Q states function is calculated, whenever Action 'ON' is > than 'OFF' trade trigger will be active
#        : Results are written to the file of the MT4 Trading Terminal
#        : Reinforcement Learning Models are created for each specific system considering 6 Market Types
#        : RL would learn to select the best Market Types to switch ON/OFF Trading Systems
# !!!!!!!!!!! #
## ATTENTION ##
# !!!!!!!!!!! #
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# THIS CODE IS NOT COMPATIBLE WITH CODE IN FOLDER _RL/TradeTriggerRL.R !!!!!!!
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
start_run <- Sys.time()
# packages used *** make sure to install these packages
library(readr)
library(stringr)
library(dplyr)
library(lubridate)
library(ReinforcementLearning)
library(magrittr)
library(lazytrade)
# ----------- Main Steps -----------------
# -- Read trading results from Terminal 1
# -- Rearrange data for RL
# -- Perform Reinforcement Learning or Update Model with New Data
# -- Start/Stop trades in Terminal 3 based on New Policy
# -- Start/Stop trades on Terminals at MacroEconomic news releases (will be covered in Course #5)
# ----------- TESTS -----------------
# -- Select entire content of the script and execute
# -- Pass: Data object DFT1 contains observations
# -- Pass: DFT1_sum contains trades summary
# -- Pass: Files SystemControlXXXXXXX.csv are generated in the Terminal 3 sandbox
# -- Pass: If file "01_MacroeconomicEvent.csv" exists trade policy is overwritten
# -- Fail: DFT1 class 'try-error'
# -- Fail: xxx
# -------------------------
# Define terminals path addresses, from where we are going to read/write data
# -------------------------
# terminal 1,3 paths
path_T1 <- normalizePath(Sys.getenv('PATH_T1'), winslash = '/')
path_T3 <- normalizePath(Sys.getenv('PATH_T3'), winslash = '/')
#path to user repo:
path_user <- normalizePath(Sys.getenv('PATH_DSS'), winslash = '/')
#path to bot setup file:
path_bot <- normalizePath(Sys.getenv('PATH_DSS_Bot'), winslash = '/')
# path with folder containing control parameters
path_control_files = file.path(path_user, "_DATA/control")
# # evaluate data on macroeconomic event (required to start trading) DSS_Bot
evaluate_macroeconomic_event(setup_file_path = path_bot,
setup_file_name = "SetupDSS_Bot.csv",
macro_event_path = path_T1,
macro_file_name = "01_MacroeconomicEvent.csv",
path_T1 = path_T1, path_T3 = path_T3)
# # evaluate data on macroeconomic event (required to start trading) DSS_Hybrid
# evaluate_macroeconomic_event(setup_file_path = "C:/Users/fxtrams/Documents/000_TradingRepo/DSS_Bot/DSS_Bots/ACTIVE",
#                              setup_file_name = "SetupDSS_Hybrid.csv",
#                              macro_event_path = path_T1,
#                              macro_file_name = "01_MacroeconomicEvent.csv",
#                              path_T1 = path_T1, path_T3 = path_T3)
#
# # evaluate data on macroeconomic event (required to start trading) FALCON_T
# evaluate_macroeconomic_event(setup_file_path = "C:/Users/fxtrams/Documents/000_TradingRepo/FALCON_T/TEST",
#                              setup_file_name = "Setup.csv",
#                              macro_event_path = path_T1,
#                              macro_file_name = "01_MacroeconomicEvent.csv",
#                              path_T1 = path_T1, path_T3 = path_T3)
# -------------------------
# read data from trades in terminal 1
# -------------------------
# # uncomment code below to test functionality without MT4 platform installed
# DFT1 <- try(import_data(trade_log_file = "_TEST_DATA/OrdersResultsT1.csv",
#                         demo_mode = T),
#             silent = TRUE)
DFT1 <- try(import_data(path_T1, "OrdersResultsT1.csv"), silent = TRUE)
# -------------------------
# read data from trades in terminal 3
# -------------------------
DFT3 <- try(import_data(path_T3, "OrdersResultsT3.csv"), silent = TRUE)
# check if we have no errors importing trading results
if(!class(DFT1)[1]=="try-error"){
# Vector with unique Trading Systems
vector_systems <- DFT1 %$% MagicNumber %>% unique() %>% sort()
# For debugging: summarise number of trades to see desired number of trades was achieved
DFT1_sum <- DFT1 %>%
group_by(MagicNumber) %>%
summarise(Num_Trades = n(),
Mean_profit = sum(Profit)) %>%
arrange(desc(Num_Trades))
### ============== FOR EVERY TRADING SYSTEM ###
for (i in 1:length(vector_systems)) {
# tryCatch() function will not abort the entire for loop in case of the error in one iteration
tryCatch({
# execute this code below for debugging:
# i <- 25
# extract current magic number id
trading_system <- vector_systems[i]
# get trading summary data only for one system
trading_systemDF <- DFT1 %>% filter(MagicNumber == trading_system)
# try to extract market type information for that system, filter rows where MarketType was not logged!
DFT1_MT <- try(mt_import_data(path_sbxm = path_T1,
system_number =  trading_system),
silent = TRUE) %>%
filter(TicketNumber != -1)
# go to the next i if there is no data
if(class(DFT1_MT)[1]=="try-error") { next }
# joining the data with market type info
trading_systemDF <- inner_join(trading_systemDF, DFT1_MT, by = "TicketNumber")
# write this data for further debugging or tests
# write_rds(trading_systemDF,path = "test_data/data_trades_markettype.rds")
if(nrow(trading_systemDF) < 10) { next }
#==============================================================================
# Define state and action sets for Reinforcement Learning
states <- c("BUN", "BUV", "BEN", "BEV", "RAN", "RAV")
actions <- c("ON", "OFF") # 'ON' and 'OFF' are referring to decision to trade with Slave system
# Define reinforcement learning parameters (see explanation below or in vignette)
# -----
# alpha - learning rate      0.1 <- slow       | fast        -> 0.9
# gamma - reward rate        0.1 <- short term | long term   -> 0.9
# epsilon - sampling rate    0.1 <- high sample| low sample  -> 0.9
# iter
# -----
# to uncomment desired learning parameters:
#control <- list(alpha = 0.5, gamma = 0.5, epsilon = 0.5)
#control <- list(alpha = 0.9, gamma = 0.9, epsilon = 0.9)
#control <- list(alpha = 0.8, gamma = 0.3, epsilon = 0.5)
#control <- list(alpha = 0.3, gamma = 0.6, epsilon = 0.1)
# check existence of the file with control parameters, go to next if not exists
if(!file.exists(paste0(path_control_files,"/", trading_system, ".rds"))) { next }
# Use optimal control parameters found by auxiliary function
control <- read_rds(paste0(path_control_files,"/", trading_system, ".rds"))
#control <- read_rds(paste0(path_control_files,"/", 8118102, ".rds"))
# -----
#==============================================================================
# perform reinforcement learning and return policy
policy_tr_systDF <- rl_generate_policy_mt(x = trading_systemDF,
states = states,
actions = actions,
control = control)
# # summarize results by Market Type
# trading_systemDF %>% group_by(MarketType) %>% summarise(ProfitMT = sum(Profit))
# record policy to the sandbox of Terminal 3, this should be analysed by EA
rl_record_policy_mt(x = policy_tr_systDF,
trading_system = trading_system,
path_terminal = path_T3,
fileName = "SystemControlMT")
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
### ============== END of FOR EVERY TRADING SYSTEM ###
} # ============== END of condition to check  if(!class(DFT1_MT)[1]=="try-error")
# Aggregate data from terminal performance and analyse results of the Terminal
# 1. Keep available data about account balance and profit
# 2. Eventually use profit data to close all trades (from DSS)
# ---- aggregate data from file Account AccountResultsT1.csv, AccountResultsT3.csv
#path to store data
acc_file_T1 <- file.path(path_user, "_DATA/AccountResultsT1.rds")
acc_file_T3 <- file.path(path_user, "_DATA/AccountResultsT3.rds")
#read data
DFT1Act <- read_csv(file.path(path_T1, 'AccountResultsT1.csv'),
col_names = c("DateTime", "Balance", "Equity","Profit"),
col_types = "cddd"
)
DFT1Act$DateTime <- ymd_hms(DFT1Act$DateTime)
#read data
DFT3Act <- read_csv(file.path(path_T3, 'AccountResultsT3.csv'),
col_names = c("DateTime", "Balance", "Equity","Profit"),
col_types = "cddd"
)
DFT3Act$DateTime <- ymd_hms(DFT3Act$DateTime)
#aggregate data, keep last 1000 records
if (!file.exists(acc_file_T1)) {
write_rds(DFT1Act, acc_file_T1)
} else {
read_rds(acc_file_T1) %>%
bind_rows(DFT1Act) %>%
arrange(DateTime) %>%
head(1000) %>%
write_rds(acc_file_T1)
}
#aggregate data, keep last 1000 records
if (!file.exists(acc_file_T3)) {
write_rds(DFT3Act, acc_file_T3)
} else {
read_rds(acc_file_T3) %>%
bind_rows(DFT3Act) %>%
arrange(DateTime) %>%
head(1000) %>%
write_rds(acc_file_T3)
}
end_run <- Sys.time()
tot_run <- end_run - start_run
print(tot_run)
